{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# '''\n",
    "# Desc:  the multi-step  LSTM model of nino index prediction, implemented by keras\n",
    "# DataSource: https://www.esrl.noaa.gov/psd/gcos_wgsp/Timeseries/\n",
    "# Reference: https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "# Author: Kris Peng\n",
    "# Date: 2018/07/24\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/chengpeng/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.models import load_model\n",
    "from numpy import array\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "    \n",
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "    # extract raw values\n",
    "    raw_values = series.values\n",
    "    # transform data to be stationary\n",
    "    diff_series = difference(raw_values, 1)\n",
    "    diff_values = diff_series.values\n",
    "    diff_values = diff_values.reshape(len(diff_values), 1)\n",
    "    # rescale values to -1, 1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    # scaled_values = diff_values\n",
    "    scaled_values = scaler.fit_transform(diff_values)\n",
    "    scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "    # transform into supervised learning problem X, y\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "    # split into train and test sets\n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "    return scaler, train, test\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    X, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "\n",
    "    # single layer LSTM\n",
    "    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "\n",
    "    # multi layer LSTM\n",
    "#     model.add(LSTM(n_neurons, return_sequences=False, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "#     model.add(LSTM(n_neurons))\n",
    "\n",
    "    # MLP Model\n",
    "    # model.add(Dense(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), activation='relu'))\n",
    "\n",
    "    # multi layer\n",
    "    # model.add(Dense(n_neurons))\n",
    "    # model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    print(model.summary())\n",
    "\n",
    "    # fit network, stateful version \n",
    "    # for i in range(nb_epoch):\n",
    "    #     history = model.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n",
    "    #     model.reset_states()\n",
    "\n",
    "    history = model.fit(X, y, epochs=nb_epoch, batch_size=n_batch, verbose=1, shuffle=False)\n",
    "    pyplot.plot(history.history['loss'])\n",
    "    pyplot.title('model loss')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['train', 'test'], loc='upper left')\n",
    "    pyplot.show()\n",
    "    return model\n",
    "\n",
    "# make one forecast with an LSTM,\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "    # reshape input pattern to [samples, timesteps, features]\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    # make forecast\n",
    "    forecast = model.predict(X, batch_size=n_batch)\n",
    "    # convert to array\n",
    "    return [x for x in forecast[0, :]]\n",
    "\n",
    "# evaluate the persistence model\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "    forecasts = list()\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        # make forecast\n",
    "        forecast = forecast_lstm(model, X, n_batch)\n",
    "        # store the forecast\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "\n",
    "# invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "    # invert first forecast\n",
    "    inverted = list()\n",
    "    inverted.append(forecast[0] + last_ob)\n",
    "    # propagate difference forecast using inverted first value\n",
    "    for i in range(1, len(forecast)):\n",
    "        inverted.append(forecast[i] + inverted[i-1])\n",
    "    return inverted\n",
    "\n",
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        # create array from forecast\n",
    "        forecast = array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        # invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        # invert differencing\n",
    "        index = len(series) - n_test + i - 1\n",
    "        last_ob = series.values[index]\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        # store\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    "\n",
    "# evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    sum_rmse = []\n",
    "    for i in range(n_seq):\n",
    "        actual = [row[i] for row in test]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        print(\"%.3f\" % rmse)\n",
    "        # print('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "        sum_rmse.append(rmse) \n",
    "    print(\"%.3f\" % ((sum_rmse[0]+sum_rmse[1]+sum_rmse[2]+sum_rmse[3]+sum_rmse[4]+sum_rmse[5])/6))\n",
    "    print(\"%.3f\" % ((sum_rmse[0]+sum_rmse[1]+sum_rmse[2]+sum_rmse[3]+sum_rmse[4]+sum_rmse[5]+sum_rmse[6]+sum_rmse[7]+sum_rmse[8])/9))\n",
    "    print(\"%.3f\" % ((sum_rmse[0]+sum_rmse[1]+sum_rmse[2]+sum_rmse[3]+sum_rmse[4]+sum_rmse[5]+sum_rmse[6]+sum_rmse[7]+sum_rmse[8]+sum_rmse[9]+sum_rmse[10]+sum_rmse[11])/12))\n",
    "    # print('6 month RMSE Avg: %f' % ((sum_rmse[0]+sum_rmse[1]+sum_rmse[2]+sum_rmse[3]+sum_rmse[4]+sum_rmse[5])/6))\n",
    "    # print('9 month RMSE Avg: %f' % ((sum_rmse[0]+sum_rmse[1]+sum_rmse[2]+sum_rmse[3]+sum_rmse[4]+sum_rmse[5]+sum_rmse[6]+sum_rmse[7]+sum_rmse[8])/9))\n",
    "    # print('12 month RMSE Avg: %f' % ((sum_rmse[0]+sum_rmse[1]+sum_rmse[2]+sum_rmse[3]+sum_rmse[4]+sum_rmse[5]+sum_rmse[6]+sum_rmse[7]+sum_rmse[8]+sum_rmse[9]+sum_rmse[10]+sum_rmse[11])/12))\n",
    "\n",
    "# plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test, linestyle = None):\n",
    "    # plot the entire dataset in blue\n",
    "    pyplot.figure(figsize=(40, 20))\n",
    "    pyplot.plot(series.values, label='observed')\n",
    "    pyplot.title(\"oni_singlevariate_multistep_timeseries\")\n",
    "    pyplot.legend(loc='upper right')\n",
    "    # plot the forecasts in red\n",
    "    print(len(forecasts))\n",
    "    for i in range(len(forecasts)):\n",
    "#         if ((324 <= i) and (i <= 348)):\n",
    "        off_s = len(series) - n_test + i - 1\n",
    "        off_e = off_s + len(forecasts[i]) + 1\n",
    "        xaxis = [x for x in range(off_s, off_e)]\n",
    "        yaxis = [series.values[off_s]] + forecasts[i]\n",
    "        pyplot.plot(xaxis, yaxis, color='red')\n",
    "#         if i%n_seq == 0 and i != 0:\n",
    "#             off_s = len(series) - n_test + i - 1\n",
    "#             off_e = off_s + len(forecasts[i]) + 1\n",
    "#             xaxis = [x for x in range(off_s, off_e)]\n",
    "#             yaxis = [series.values[off_s]] + forecasts[i]\n",
    "#             pyplot.plot(xaxis, yaxis, color='red')\n",
    "    # show the plot\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "series = read_csv('../../data/oni/csv/nino3_4_anomaly.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "\n",
    "# configure\n",
    "n_lag = 12\n",
    "n_seq = 12\n",
    "n_test = 360\n",
    "n_epochs = 30\n",
    "n_batch = 1\n",
    "n_neurons = 10\n",
    "\n",
    "# LSTM model\n",
    "\n",
    "# prepare data\n",
    "scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "\n",
    "# fit model\n",
    "file_path = 'my_model.h5'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)\n",
    "    model.save(file_path)\n",
    "else:\n",
    "    model = load_model(file_path)\n",
    "\n",
    "# make forecasts\n",
    "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n",
    "# inverse transform forecasts and test\n",
    "forecasts = inverse_transform(series, forecasts, scaler, n_test+11)\n",
    "actual = [row[n_lag:] for row in test]\n",
    "actual = inverse_transform(series, actual, scaler, n_test+11)\n",
    "# evaluate forecasts\n",
    "minlist = []\n",
    "for i in range(345, len(actual)):\n",
    "    absvalue = 0\n",
    "    for j in range(len(actual[i])-3):\n",
    "        absvalue = absvalue + (actual[i][j]- forecasts[i][j])**2\n",
    "    minlist.append(absvalue)\n",
    "print(len(minlist))\n",
    "print('--')\n",
    "print(min(minlist))\n",
    "print(minlist.index(min(minlist)))\n",
    "print(actual[minlist.index(min(minlist))+345])\n",
    "print(forecasts[minlist.index(min(minlist))+345])\n",
    "print('--')\n",
    "# evaluate_forecasts(actual, forecasts, n_lag, n_seq)\n",
    "# plot forecasts\n",
    "plot_forecasts(series[-n_test:], forecasts, n_test+11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
